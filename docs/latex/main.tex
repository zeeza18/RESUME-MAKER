\documentclass[letterpaper,11pt]{article}
\usepackage{latexsym}
\usepackage[empty]{fullpage}
\usepackage{titlesec}
\usepackage{marvosym}
\usepackage[usenames,dvipsnames]{color}
\usepackage{verbatim}
\usepackage{enumitem}
\usepackage[hidelinks]{hyperref}
\usepackage{fancyhdr}
\usepackage[english]{babel}
\usepackage{tabularx}
\input{glyphtounicode}

\pagestyle{fancy}
\fancyhf{}
\fancyfoot{}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

\addtolength{\oddsidemargin}{-0.65in}
\addtolength{\evensidemargin}{-0.65in}
\addtolength{\textwidth}{1.3in}
\addtolength{\topmargin}{-0.7in}
\addtolength{\textheight}{1.25in}

\urlstyle{same}
\raggedbottom
\raggedright
\setlength{\tabcolsep}{0in}

\titleformat{\section}{
  \vspace{-6pt}\scshape\raggedright\large
}{}{0em}{}[\color{black}\titlerule \vspace{-6pt}]

\pdfgentounicode=1
\setlist[itemize]{leftmargin=*, topsep=2pt, itemsep=2pt, parsep=0pt, partopsep=0pt}
\setlength{\parskip}{1pt}
\renewcommand{\baselinestretch}{0.96}

\newcommand{\resumeItem}[1]{\item\small{{#1 \vspace{-3pt}}}}
\newcommand{\resumeSubheading}[4]{
  \vspace{-3pt}\item
    \begin{tabularx}{0.995\textwidth}[t]{Xr}
      \textbf{#1} & #2 \\
      \textit{\small#3} & \textit{\small #4} \\
    \end{tabularx}\\[-3pt]
    \vspace{3pt}
}
\newcommand{\resumeProjectHeading}[2]{
    \vspace{-3pt}\item
    \begin{tabularx}{0.995\textwidth}[t]{Xr}
      \small\textbf{#1} & #2 \\
    \end{tabularx}\\[-3pt]
    \vspace{3pt}
}
\newcommand{\resumeItemListStart}{\begin{itemize}}
\newcommand{\resumeItemListEnd}{\end{itemize}\vspace{-4pt}}
\newcommand{\resumeSubHeadingListStart}{
  \begin{itemize}[leftmargin=0.12in, label={}]
  \setlength{\itemsep}{0pt}
  \setlength{\parsep}{0pt}
  \setlength{\parskip}{0pt}
}
\newcommand{\resumeSubHeadingListEnd}{\end{itemize}}

\begin{document}

\begin{center}
    \textbf{\Huge \scshape Mohammed Azeezulla} \\ \vspace{1pt}
    \small\textsc{Artificial Intelligence} \\ \vspace{1pt}
    \small USA $|$ (872)330-2122 $|$ \href{mailto:Mohammedazeezulla6996@gmail.com}{\underline{Mohammedazeezulla6996@gmail.com}} $|$ \href{https://linkedin.com}{\underline{LinkedIn}} $|$ \href{https://github.com}{\underline{GitHub}} $|$ \href{https://portfolio.com}{\underline{Portfolio}}
\end{center}

\section{Summary}
\vspace{-4pt}
\small{Experienced AI Engineer with around 3 years of experience building and deploying end-to-end AI solutions for the finance domain, including risk analytics, credit modeling, fraud detection, and portfolio intelligence. Proficient in LLMs, transformer architectures, multimodal reasoning, and automated evaluation pipelines to improve model performance and reliability. Strong expertise in financial data processing, MLOps, and scalable deployments using Spark, Airflow, AWS SageMaker, and Docker-based microservices, delivering production-ready, explainable AI systems aligned with regulatory, audit, and business requirements.}
\vspace{2pt}

\section{Skills}
\vspace{-4pt}
\begin{itemize}[leftmargin=0in, label={}, itemsep=1pt, topsep=2pt, parsep=0pt]
    \item \small{\textbf{Programming Languages:} Python, SQL, Bash}
    \item \small{\textbf{Machine Learning \& Statistical Modeling:} Scikit-Learn, XGBoost, LightGBM, Feature Engineering, Classical ML Algorithms, Anomaly Detection Models, Model Evaluation, SHAP Explainability}
    \item \small{\textbf{Deep Learning \& GenAI Tools:} TensorFlow, Keras, PyTorch, MXNet, Autoencoders, LSTM Networks, Attention Mechanisms, Transformers, Generative Models, Multimodal Models, Vector Embeddings, Token-Level Reasoning}
    \item \small{\textbf{Large Language Models \& GenAI Frameworks:} OpenAI Models, Claude, LlamaIndex, Gemini, LangChain, CrewAI, Retrieval-Augmented Generation (RAG), LLM Inspectors, Prompt Engineering, Multi-Agent AI Systems, Embedding-Based Retrieval}
    \item \small{\textbf{MLOps, Deployment \& Model Lifecycle:} MLflow, Airflow, AWS SageMaker, Docker, Kubernetes, CI/CD for ML Systems, GitLab CI/CD, Model Monitoring, Experiment Tracking, Automated Scoring Pipelines}
    \item \small{\textbf{AI Testing, Evaluation \& Automation:} Playwright, PyTest, Agentic AI Testing, Structured Extraction Pipelines, Representation Alignment, Semantic Scoring, Vector Stores, Automated Evaluation Frameworks}
    \item \small{\textbf{Big Data \& Real-Time Processing:} Apache Spark, PySpark, Kafka, Hadoop, HDFS, Hive, Databricks, Redis, Elasticsearch, Real-Time Streaming Pipelines, Event-Driven Processing}
    \item \small{\textbf{Cloud Platforms, Databases \& Visualization:} AWS (Lambda, S3, EC2, SageMaker, Bedrock), Azure Cognitive Services, Azure AI ML Services, PostgreSQL, SQL Databases, Power BI, Tableau, Compliance Dashboards, JSON-Based Data Mapping}
    \item \small{\textbf{Web \& API Services:} FastAPI, Flask, HTML, CSS, Front-End Web Frameworks, React, TypeScript}
    \item \small{\textbf{AI Concepts \& Principles:} NLP, Deep Learning, Clustering, Regression, Algorithm Selection, Algorithm Evaluation, AI-Enabled Systems, AI Principles}
\end{itemize}

\section{Experience}
\resumeSubHeadingListStart
    \resumeSubheading
      {State Street}{Oct 2025 - Present}
      {AI Engineer}{USA}
    \resumeItemListStart
        \resumeItem{Architected a GenAI investment intelligence solution using OpenAI large language models and retrieval-augmented reasoning, reducing manual portfolio risk analysis effort by 45\% for investment teams.}
        \resumeItem{Constructed a semantic retrieval layer with LangChain and vector-based NLP search to unify trades, benchmarks, and regulations, improving natural language portfolio insight accuracy by 38\%.}
        \resumeItem{Developed finance-aware transformer models using Hugging Face architectures to strengthen investment terminology understanding, decreasing incorrect financial explanations by 30\% during volatile market review cycles.}
        \resumeItem{Operationalized scalable GenAI inference through containerized Docker deployment and governed MLOps orchestration, enabling secure fintech AI usage and increasing analytics platform adoption by 28\%.}
        \resumeItem{Synthesized pricing signals, liquidity metrics, and performance drivers into RAG-based investment narratives, improving portfolio explanation clarity by 40\% and reducing reporting preparation effort by 35\%.}
    \resumeItemListEnd

    \resumeSubheading
      {TekAnthem}{Jun 2025 - Sep 2025}
      {Artificial Intelligence Engineer (Remote)}{USA}
    \resumeItemListStart
        \resumeItem{Engineered an Agentic AI testing workflow using CrewAI and Python to replace unreliable manual validation, refine LLM prompt behavior, automate multi-agent evaluations, and elevate testing efficiency by nearly 60\%.}
        \resumeItem{Devised a structured-extraction pipeline using representation learning and Azure AI ML Services to handle inconsistent UI layouts, design JSON-based output mapping, generate reusable backend objects, and achieve nearly 90\% accuracy.}
        \resumeItem{Coordinated Claude-driven automation with Playwright and PyTest to strengthen fragile test flows, introduce retrieval-augmented prompts, embed redundancy logic, and improve test-recovery performance by around 70\%.}
        \resumeItem{Constructed multimodal evaluation dashboards with OpenAI, LangChain, and embedding-based scoring to overcome inconsistent model reviews, formalize validation workflows, standardize AI safety checks, and increase stakeholder adoption to roughly 90\%.}
        \resumeItem{Advanced the AI quality-assurance lifecycle by integrating Gemini, vector stores, and LLM-based inspectors to fix inconsistent monitoring, enforce unified scoring metrics, automate research validation, and accelerate deployment cycles by nearly 40\%.}
    \resumeItemListEnd

    \resumeSubheading
      {Streebo Inc}{Sep 2021 - Dec 2023}
      {Machine Learning Engineer}{India}
    \resumeItemListStart
        \resumeItem{Engineered a financial risk intelligence pipeline by unifying borrower histories, bureau files, salary documents, and payment streams, and optimized feature extraction using Spark, PySpark, SQL, credit-bureau APIs, AML/KYC modules, and OCR parsers, boosting credit-risk readiness by over 42\% and improving stability assessment through refined Power BI insights.}
        \resumeItem{Formulated advanced credit-default and fraud-likelihood models with LightGBM, Scikit-Learn, and TensorFlow while aligning model architecture with loan decision workflows and orchestrated retraining, bias checks, and MLflow versioning which elevated scoring precision by over 31\% and supported loan officers with SHAP-driven financial explainability.}
        \resumeItem{Engineered Kafka streaming with Spark, Redis, AWS services, and fraud-scoring/AML monitoring feeds to detect transaction velocity shifts, merchant anomalies, and geo-behavior outliers, and refined Autoencoder-based anomaly logic across compliance checkpoints, boosting fraud-capture consistency by over 37\% and improving analyst case reviews in Tableau.}
        \resumeItem{Directed Airflow-based scoring cycles and SageMaker deployments by standardizing batch and streaming inference paths for risk and fraud modules and optimized orchestration and alert delivery using Elasticsearch insights which reduced manual intervention for financial risk units by over 40\% through stable automation and rapid scoring turnaround.}
        \resumeItem{Executed unified microservice deployments across Docker and Kubernetes while embedding regulatory checkpoints into finance workflows and synthesized model interpretability, account-level traceability, and transaction-level audit trails which improved analytic reliability by over 29\% and positioned the platform to support secure lending operations and scalable payment monitoring.}
    \resumeItemListEnd
\resumeSubHeadingListEnd

\section{Education}
\resumeSubHeadingListStart
    \resumeSubheading
      {DePaul University}{Nov 2025}
      {Masters, Artificial Intelligence}{USA}
    \resumeSubheading
      {MVJ College of Engineering}{Jun 2023}
      {Bachelors, Computer Science and Engineering}{India}
\resumeSubHeadingListEnd

\section{Certificates}
\vspace{-4pt}
\resumeItemListStart
    \resumeItem{Microsoft GENAI}
    \resumeItem{Infosys Introduction to AI}
    \resumeItem{All India Visonet AI Hackathon}
    \resumeItem{Internshala Data Science}
    \resumeItem{Internshala Deep Learning}
\resumeItemListEnd

\section{Projects}
\resumeSubHeadingListStart
    \resumeProjectHeading
      {Multi-Stage LLM Application with RL Fine-Tuning and RAG}{}
    \resumeItemListStart
        \resumeItem{Engineered a multi-stage GenAI application by fine-tuning a Qwen model for task-specific reasoning, applying GRPO training with a five-level evaluation framework built on Unsloth, and validating output quality through structured scoring logic.}
        \resumeItem{Integrated and deployed a real-time RAG system by connecting search APIs sourced from Wikipedia and Google SERP, implementing LlamaIndex for contextual retrieval, optimizing inference with vLLM, and delivering a React and TypeScript frontend with a FastAPI backend deployed on Vercel and Render.}
    \resumeItemListEnd

    \resumeProjectHeading
      {Skin Disease Analyzer with Enhancement in VGG19 Algorithm}{}
    \resumeItemListStart
        \resumeItem{Developed a Flask-based medical-image analysis system using a curated 10k dermatology dataset, integrating condition-specific recommendation APIs and delivering scalable, real-time skin-disease classification for 50+ users with consistent diagnostic support.}
        \resumeItem{Fine-tuned VGG19 with optimized preprocessing, augmentation, and selective layer unfreezing, achieving 94\% accuracy while reducing overfitting, and validated the end-to-end pipeline through safety checks, logging, and evaluation workflows presented at IEEE 2023.}
    \resumeItemListEnd
    
    \resumeProjectHeading
      {Symptoms to Solution}{}
    \resumeItemListStart
        \resumeItem{Designed a symptom-to-disease prediction engine using a 10K+ healthcare dataset and 132 severity-weighted features, applying structured data-modeling techniques to enhance interpretability and strengthen clinical decision-support accuracy.}
        \resumeItem{Optimized ML models including Decision Trees, Random Forest, XGBoost, AdaBoost, and SVM using cross-validation and hyperparameter tuning, deploying a normalized SVM that achieved 78\% accuracy with improved runtime efficiency for scalable prediction workflows.}
    \resumeItemListEnd
\resumeSubHeadingListEnd

\end{document}